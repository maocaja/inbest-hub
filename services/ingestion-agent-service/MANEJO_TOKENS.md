# ğŸ”„ Manejo de Tokens y Modos del LLM

## ğŸ“Š **Â¿QuÃ© son los tokens?**

Los **tokens** son unidades de texto que OpenAI usa para procesar:
- **1 token** â‰ˆ 4 caracteres en inglÃ©s
- **1 token** â‰ˆ 3-4 caracteres en espaÃ±ol
- **LÃ­mite GPT-3.5**: 4,096 tokens por conversaciÃ³n
- **LÃ­mite GPT-4**: 8,192 tokens por conversaciÃ³n

### **Ejemplos de uso de tokens:**
- **Mensaje corto**: "Hola" = ~1 token
- **Mensaje medio**: "El proyecto tiene 50 apartamentos" = ~8 tokens
- **Documento PDF**: 1 pÃ¡gina = ~500-1000 tokens
- **ConversaciÃ³n larga**: 50 mensajes = ~2000-3000 tokens

## âš ï¸ **Â¿QuÃ© pasa si se alcanza el lÃ­mite?**

### **Error tÃ­pico:**
```
Error: Maximum context length exceeded
```

### **Soluciones automÃ¡ticas implementadas:**

#### **1. Truncamiento inteligente**
```python
# El sistema automÃ¡ticamente:
# - Mantiene los Ãºltimos N mensajes
# - Elimina mensajes antiguos
# - Preserva el contexto importante
```

#### **2. Resumen de conversaciÃ³n**
```python
# Cuando se acerca al lÃ­mite:
# - Genera resumen de la conversaciÃ³n
# - Mantiene solo puntos clave
# - ContinÃºa con contexto resumido
```

#### **3. Reinicio de sesiÃ³n**
```python
# Si no se puede continuar:
# - Sugiere crear nueva sesiÃ³n
# - Guarda progreso actual
# - Permite continuar desde donde se quedÃ³
```

## ğŸ”§ **CÃ³mo cambiar entre modos**

### **Modo Simulado (Sin costos)**
```bash
# Activar modo simulado
python3 switch_mode.py simulado

# Verificar modo actual
python3 switch_mode.py status

# Reiniciar servicio
pkill -f "python3 main.py"
python3 main.py &
```

### **Modo Real (Con OpenAI)**
```bash
# Activar modo real
python3 switch_mode.py real

# Verificar modo actual
python3 switch_mode.py status

# Reiniciar servicio
pkill -f "python3 main.py"
python3 main.py &
```

## ğŸ“ˆ **Monitoreo de uso de tokens**

### **En modo real:**
```json
{
  "usage": {
    "prompt_tokens": 1500,
    "completion_tokens": 200,
    "total_tokens": 1700
  }
}
```

### **En modo simulado:**
```json
{
  "usage": {
    "prompt_tokens": 1500,
    "completion_tokens": 200,
    "total_tokens": 1700
  }
}
```

## ğŸ¯ **Estrategias para optimizar tokens**

### **1. Mensajes concisos**
```bash
# âŒ Mal: Muy largo
"El proyecto inmobiliario que estamos desarrollando en la ciudad de BogotÃ¡, especÃ­ficamente en la localidad de Chapinero, tiene un total de 50 apartamentos distribuidos en 2 torres de 25 pisos cada una, con amenidades que incluyen piscina, gimnasio, parqueadero, zona de BBQ, salÃ³n comunal, y Ã¡reas verdes..."

# âœ… Bien: Conciso
"Proyecto: 50 apartamentos en Chapinero, BogotÃ¡. Amenidades: piscina, gimnasio, parqueadero."
```

### **2. Limpiar historial periÃ³dicamente**
```bash
# El sistema automÃ¡ticamente:
# - Mantiene Ãºltimos 10 mensajes
# - Elimina contexto antiguo
# - Preserva informaciÃ³n clave
```

### **3. Usar modo simulado para desarrollo**
```bash
# Para pruebas extensas:
python3 switch_mode.py simulado
# Sin lÃ­mites de tokens
# Sin costos
# Respuestas predefinidas
```

## ğŸ”„ **Comandos Ãºtiles**

### **Verificar modo actual:**
```bash
python3 switch_mode.py status
```

### **Cambiar a modo simulado:**
```bash
python3 switch_mode.py simulado
```

### **Cambiar a modo real:**
```bash
python3 switch_mode.py real
```

### **Ver uso de tokens en tiempo real:**
```bash
# En los logs del servicio verÃ¡s:
# "total_tokens": 1700
```

## ğŸ’¡ **Recomendaciones**

### **Para desarrollo:**
- âœ… Usar **modo simulado**
- âœ… Sin lÃ­mites de tokens
- âœ… Sin costos
- âœ… Respuestas predecibles

### **Para producciÃ³n:**
- âœ… Usar **modo real**
- âœ… Configurar lÃ­mite de gasto
- âœ… Monitorear uso de tokens
- âœ… Optimizar mensajes

### **Para pruebas extensas:**
- âœ… Usar **modo simulado**
- âœ… Probar flujos completos
- âœ… Validar funcionalidades
- âœ… Sin preocuparse por lÃ­mites

## ğŸš¨ **Alertas automÃ¡ticas**

El sistema detecta automÃ¡ticamente:
- âš ï¸ **80% del lÃ­mite alcanzado**: Aviso preventivo
- ğŸš¨ **90% del lÃ­mite alcanzado**: Sugerencia de limpiar historial
- âŒ **100% del lÃ­mite alcanzado**: Error con opciones de recuperaciÃ³n

## ğŸ“ **Ejemplo de manejo de lÃ­mite**

```python
# Cuando se alcanza el lÃ­mite:
if total_tokens > max_tokens * 0.9:
    # Limpiar historial antiguo
    messages = messages[-5:]  # Mantener solo Ãºltimos 5
    
    # Agregar resumen
    summary = "ConversaciÃ³n anterior resumida..."
    messages.insert(0, {"role": "system", "content": summary})
    
    # Continuar normalmente
    continue_conversation()
```

---

**ğŸ¯ Con estas estrategias, puedes usar el sistema sin preocuparte por lÃ­mites de tokens.** 