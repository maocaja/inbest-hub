#!/usr/bin/env python3
"""
Modo de prueba para simular respuestas del LLM sin usar OpenAI
"""

import json
import random
from typing import List, Dict, Any

class MockLLMService:
    """
    Servicio LLM simulado para pruebas sin OpenAI
    """
    
    def __init__(self):
        self.responses = {
            "greeting": [
                "¬°Hola! Soy tu asistente para proyectos inmobiliarios. ¬øEn qu√© puedo ayudarte hoy?",
                "Hola, estoy aqu√≠ para ayudarte a completar la informaci√≥n de tu proyecto. ¬øQu√© necesitas?",
                "¬°Bienvenido! Soy tu asistente inmobiliario. ¬øC√≥mo puedo ayudarte?"
            ],
            "project_info": [
                "Perfecto, he anotado la informaci√≥n del proyecto. ¬øPodr√≠as darme m√°s detalles sobre la ubicaci√≥n?",
                "Excelente, he registrado los datos. ¬øSabes cu√°l es el precio por unidad?",
                "Muy bien, he guardado esa informaci√≥n. ¬øCu√°les son las amenidades del proyecto?"
            ],
            "missing_fields": [
                "Veo que faltan algunos campos importantes. Necesitamos completar: precio, ubicaci√≥n exacta, y amenidades.",
                "Para completar el proyecto necesitamos: informaci√≥n de contacto, detalles financieros, y fecha de entrega.",
                "Faltan algunos datos clave: NIT de la constructora, √°rea de las unidades, y opciones de financiaci√≥n."
            ],
            "completion": [
                "¬°Excelente! El proyecto est√° casi completo. Solo faltan algunos detalles menores.",
                "Muy bien, hemos completado la mayor√≠a de la informaci√≥n. ¬øQuieres que genere una descripci√≥n profesional?",
                "Perfecto, el proyecto est√° completo. ¬øTe gustar√≠a que lo guarde en el sistema?"
            ]
        }
    
    def generate_response(self, messages: List[Dict[str, str]], tools: List[Dict] = None) -> Dict[str, Any]:
        """
        Generar respuesta simulada del LLM
        """
        try:
            # Simular procesamiento
            last_message = messages[-1]["content"].lower() if messages else ""
            
            # Determinar tipo de respuesta basado en el mensaje
            if "hola" in last_message or "ayuda" in last_message:
                response_type = "greeting"
            elif "proyecto" in last_message and ("tiene" in last_message or "es" in last_message):
                response_type = "project_info"
            elif "falta" in last_message or "completar" in last_message:
                response_type = "missing_fields"
            elif "completo" in last_message or "terminado" in last_message:
                response_type = "completion"
            else:
                response_type = "project_info"
            
            # Seleccionar respuesta aleatoria
            response = random.choice(self.responses[response_type])
            
            # Simular tool calls ocasionalmente
            tool_calls = None
            if "nit" in last_message and "900123456-7" in last_message:
                tool_calls = [{
                    "id": f"call_{random.randint(1000, 9999)}",
                    "function": {
                        "name": "get_project_owner_info",
                        "arguments": json.dumps({"nit": "900123456-7"})
                    },
                    "type": "function"
                }]
            
            return {
                "success": True,
                "response": response,
                "tool_calls": tool_calls,
                "usage": {
                    "prompt_tokens": len(str(messages)),
                    "completion_tokens": len(response),
                    "total_tokens": len(str(messages)) + len(response)
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Error en LLM simulado: {str(e)}"
            }
    
    def extract_project_info(self, document_text: str) -> Dict[str, Any]:
        """
        Extraer informaci√≥n del proyecto de manera simulada
        """
        # Simular extracci√≥n de datos
        extracted_data = {
            "name": "Proyecto Extra√≠do",
            "location": "Ubicaci√≥n Detectada",
            "price": "Precio Estimado",
            "units": "N√∫mero de Unidades"
        }
        
        return {
            "success": True,
            "extracted_data": extracted_data
        }
    
    def validate_project_data(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validar datos del proyecto de manera simulada
        """
        return {
            "success": True,
            "is_valid": True,
            "validation_errors": []
        }
    
    def generate_project_description(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generar descripci√≥n del proyecto de manera simulada
        """
        description = f"""
        Proyecto inmobiliario {project_data.get('name', '')} ubicado en {project_data.get('location', '')}.
        Este desarrollo ofrece {project_data.get('units', '')} con precios desde {project_data.get('price', '')}.
        Incluye amenidades como piscina, gimnasio y parqueadero. Entrega programada para 2025.
        """
        
        return {
            "success": True,
            "description": description.strip()
        }

def test_mock_llm():
    """
    Probar el servicio LLM simulado
    """
    print("üß™ Probando LLM simulado...")
    
    mock_llm = MockLLMService()
    
    # Test 1: Respuesta de saludo
    messages = [{"role": "user", "content": "Hola, necesito ayuda"}]
    response = mock_llm.generate_response(messages)
    print(f"‚úÖ Respuesta de saludo: {response['response'][:50]}...")
    
    # Test 2: Informaci√≥n del proyecto
    messages = [{"role": "user", "content": "El proyecto tiene 50 apartamentos"}]
    response = mock_llm.generate_response(messages)
    print(f"‚úÖ Respuesta de proyecto: {response['response'][:50]}...")
    
    # Test 3: Tool calling
    messages = [{"role": "user", "content": "El NIT es 900123456-7"}]
    response = mock_llm.generate_response(messages)
    if response.get('tool_calls'):
        print(f"‚úÖ Tool calling simulado: {response['tool_calls'][0]['function']['name']}")
    else:
        print("‚ÑπÔ∏è  No se activ√≥ tool calling")
    
    print("‚úÖ LLM simulado funcionando correctamente")

if __name__ == "__main__":
    test_mock_llm() 