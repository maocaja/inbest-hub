#!/usr/bin/env python3
"""
Tests b√°sicos para Ingestion Agent Service
"""

import sys
import os
import json
import requests
from pathlib import Path

# Agregar el directorio actual al path para importar m√≥dulos
sys.path.append(str(Path(__file__).parent))

def test_imports():
    """Test de importaciones b√°sicas"""
    print("üß™ Probando importaciones...")

    try:
        from config import Config
        print("‚úÖ Config importado correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando Config: {e}")
        return False

    try:
        from database.database import get_db, engine
        print("‚úÖ Database importado correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando database: {e}")
        return False

    try:
        from models.models import ConversationSession, ConversationMessage, DocumentUpload
        print("‚úÖ Models importados correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando models: {e}")
        return False

    try:
        from schemas.schemas import IngestionStartRequest, ChatMessageRequest
        print("‚úÖ Schemas importados correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando schemas: {e}")
        return False

    try:
        from services.ingestion_service import IngestionService
        print("‚úÖ IngestionService importado correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando IngestionService: {e}")
        return False

    try:
        from utils.document_processor import DocumentProcessor
        print("‚úÖ DocumentProcessor importado correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando DocumentProcessor: {e}")
        return False

    try:
        from services.llm_service import LLMService
        print("‚úÖ LLMService importado correctamente")
    except ImportError as e:
        print(f"‚ùå Error importando LLMService: {e}")
        return False

    return True

def test_config():
    """Test de configuraci√≥n"""
    print("\nüß™ Probando configuraci√≥n...")

    try:
        from config import Config

        # Verificar configuraci√≥n b√°sica
        assert hasattr(Config, 'PORT'), "Config debe tener PORT"
        assert hasattr(Config, 'DATABASE_URL'), "Config debe tener DATABASE_URL"
        assert hasattr(Config, 'OPENAI_API_KEY'), "Config debe tener OPENAI_API_KEY"

        print(f"‚úÖ Puerto configurado: {Config.PORT}")
        print(f"‚úÖ Base de datos: {Config.DATABASE_URL}")
        print(f"‚úÖ OpenAI API Key configurada: {'S√≠' if Config.OPENAI_API_KEY else 'No'}")

        # Validar configuraci√≥n
        errors = Config.validate_config()
        if errors:
            print(f"‚ö†Ô∏è  Errores de configuraci√≥n: {errors}")
            return False
        else:
            print("‚úÖ Configuraci√≥n v√°lida")
            return True

    except Exception as e:
        print(f"‚ùå Error en configuraci√≥n: {e}")
        return False

def test_database_connection():
    """Test de conexi√≥n a base de datos"""
    print("\nüß™ Probando conexi√≥n a base de datos...")

    try:
        from database.database import engine
        from models.models import Base
        from sqlalchemy import text

        # Crear tablas
        Base.metadata.create_all(bind=engine)
        print("‚úÖ Tablas creadas correctamente")

        # Probar conexi√≥n
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            result.fetchone()  # Ejecutar la consulta
            print("‚úÖ Conexi√≥n a base de datos exitosa")

        return True

    except Exception as e:
        print(f"‚ùå Error de conexi√≥n a base de datos: {e}")
        return False

def test_document_processor():
    """Test del procesador de documentos"""
    print("\nüß™ Probando procesador de documentos...")

    try:
        from utils.document_processor import DocumentProcessor

        processor = DocumentProcessor()
        print("‚úÖ DocumentProcessor instanciado correctamente")

        # Verificar formatos soportados
        formats = processor.get_supported_formats()
        print(f"‚úÖ Formatos soportados: {formats}")

        # Test de validaci√≥n de archivo
        test_file = "test_document.txt"
        with open(test_file, "w") as f:
            f.write("Test document content")

        validation = processor.validate_file(test_file)
        print(f"‚úÖ Validaci√≥n de archivo: {validation['valid']}")

        # Limpiar archivo de prueba
        if os.path.exists(test_file):
            os.remove(test_file)

        return True

    except Exception as e:
        print(f"‚ùå Error en procesador de documentos: {e}")
        return False

def test_llm_service():
    """Test del servicio LLM"""
    print("\nüß™ Probando servicio LLM...")

    try:
        from services.llm_service import LLMService
        from config import Config

        if not Config.OPENAI_API_KEY or Config.OPENAI_API_KEY == "your_openai_api_key_here":
            print("‚ö†Ô∏è  OpenAI API Key no configurada, saltando test de LLM")
            return True

        llm_service = LLMService()
        print("‚úÖ LLMService instanciado correctamente")

        # Test b√°sico de generaci√≥n de respuesta
        test_messages = [
            {"role": "user", "content": "Hola, ¬øc√≥mo est√°s?"}
        ]

        response = llm_service.generate_response(test_messages)
        if response["success"]:
            print("‚úÖ Respuesta LLM generada correctamente")
        else:
            print(f"‚ö†Ô∏è  Error en LLM: {response.get('error', 'Unknown error')}")

        return True

    except Exception as e:
        print(f"‚ùå Error en servicio LLM: {e}")
        return False

def test_ingestion_service():
    """Test del servicio de ingesti√≥n"""
    print("\nüß™ Probando servicio de ingesti√≥n...")

    try:
        from services.ingestion_service import IngestionService
        from database.database import SessionLocal

        service = IngestionService()
        print("‚úÖ IngestionService instanciado correctamente")

        # Crear sesi√≥n de prueba
        db = SessionLocal()
        print("‚úÖ Sesi√≥n de base de datos creada")

        return True

    except Exception as e:
        print(f"‚ùå Error en servicio de ingesti√≥n: {e}")
        return False

def test_fastapi_routes():
    """Test de rutas FastAPI"""
    print("\nüß™ Probando rutas FastAPI...")

    try:
        from main import app

        # Verificar rutas b√°sicas
        routes = [
            "/",
            "/health",
            "/ingest/start",
            "/ingest/message",
            "/ingest/status/{session_id}",
            "/ingest/upload",
            "/ingest/generate-description",
            "/ingest/supported-formats"
        ]

        app_routes = [route.path for route in app.routes]

        for route in routes:
            if route in app_routes:
                print(f"‚úÖ Ruta {route} encontrada")
            else:
                print(f"‚ö†Ô∏è  Ruta {route} no encontrada")

        return True

    except Exception as e:
        print(f"‚ùå Error en rutas FastAPI: {e}")
        return False

def test_api_endpoints():
    """Test de endpoints API (requiere servidor corriendo)"""
    print("\nüß™ Probando endpoints API...")

    base_url = "http://localhost:8004"

    try:
        # Health check
        response = requests.get(f"{base_url}/health", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Health check exitoso")
        else:
            print(f"‚ö†Ô∏è  Health check fall√≥: {response.status_code}")
            return False

        # Root endpoint
        response = requests.get(f"{base_url}/", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Root endpoint exitoso")
        else:
            print(f"‚ö†Ô∏è  Root endpoint fall√≥: {response.status_code}")
            return False

        # Supported formats endpoint
        response = requests.get(f"{base_url}/ingest/supported-formats", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Supported formats endpoint exitoso")
        else:
            print(f"‚ö†Ô∏è  Supported formats endpoint fall√≥: {response.status_code}")
            return False

        return True

    except requests.exceptions.ConnectionError:
        print("‚ö†Ô∏è  Servidor no est√° corriendo (esto es normal si no se ha iniciado)")
        return True
    except Exception as e:
        print(f"‚ùå Error en endpoints API: {e}")
        return False

def test_openai_integration():
    """Test de integraci√≥n con OpenAI"""
    print("\nüß™ Probando integraci√≥n con OpenAI...")

    try:
        from config import Config

        if not Config.OPENAI_API_KEY or Config.OPENAI_API_KEY == "your_openai_api_key_here":
            print("‚ö†Ô∏è  OpenAI API Key no configurada, saltando test de integraci√≥n")
            return True

        # Test b√°sico de conexi√≥n con OpenAI
        import openai
        client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)
        
        # Test simple de chat
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Hola"}],
            max_tokens=10
        )
        
        if response.choices:
            print("‚úÖ Integraci√≥n con OpenAI exitosa")
            return True
        else:
            print("‚ö†Ô∏è  Respuesta vac√≠a de OpenAI")
            return False

    except Exception as e:
        print(f"‚ùå Error en integraci√≥n con OpenAI: {e}")
        return False

def main():
    """Funci√≥n principal de tests"""
    print("üß™ Iniciando tests b√°sicos para Ingestion Agent Service...")
    print("="*70)

    tests = [
        ("Importaciones", test_imports),
        ("Configuraci√≥n", test_config),
        ("Base de datos", test_database_connection),
        ("Procesador de documentos", test_document_processor),
        ("Servicio LLM", test_llm_service),
        ("Servicio de ingesti√≥n", test_ingestion_service),
        ("Rutas FastAPI", test_fastapi_routes),
        ("Endpoints API", test_api_endpoints),
        ("Integraci√≥n OpenAI", test_openai_integration)
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                print(f"‚ùå Test '{test_name}' fall√≥")
        except Exception as e:
            print(f"‚ùå Test '{test_name}' fall√≥ con excepci√≥n: {e}")

    print("\n" + "="*70)
    print(f"üìä Resultados: {passed}/{total} tests pasaron")

    if passed == total:
        print("üéâ ¬°Todos los tests pasaron!")
        return 0
    else:
        print("‚ö†Ô∏è  Algunos tests fallaron")
        return 1

if __name__ == "__main__":
    sys.exit(main())
